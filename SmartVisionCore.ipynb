{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3602a8a-4673-44b6-8281-621c12b6aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Installation\n",
    "\n",
    "# !pip install ultralytics opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0809d-48bb-4025-ac43-f83b3f2314e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import necessary libraries.\n",
    "import os\n",
    "import shutil # shutil was imported in the original cell 2, ensure it's available or re-import if running cells independently\n",
    "from ultralytics import YOLO # YOLO was imported in cell 2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt # plt was imported in cell 2\n",
    "import numpy as np # For converting image bytes\n",
    "import requests # For downloading the image from URL\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f90aa-1e9b-429a-81cc-cde81cee3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Paths and Dataset Configuration.\n",
    "\n",
    "# Path to the dataset configuration YAML file.\n",
    "# This file should be inside the dataset folder.\n",
    "DATASET_YAML_PATH = 'datasets/fall_detection_dataset_2/data.yaml'\n",
    "\n",
    "# Check if the YAML file exists (basic check).\n",
    "if not os.path.exists(DATASET_YAML_PATH):\n",
    "    print(f\"ERROR: Dataset YAML file not found at '{DATASET_YAML_PATH}'\")\n",
    "    print(\"Please ensure you have created your dataset and the data.yaml file, then update DATASET_YAML_PATH.\")\n",
    "else:\n",
    "    print(f\"Dataset YAML path: {DATASET_YAML_PATH}\")\n",
    "\n",
    "# Path to a sample image for testing inference (after training).\n",
    "# Create a 'test_samples' folder in your project directory and add some images/videos.\n",
    "SAMPLE_IMAGE_PATH = 'test_samples/sample_fall_image.jpg'\n",
    "SAMPLE_VIDEO_PATH = 'test_samples/test_video.mp4'\n",
    "\n",
    "# Create a dummy sample image if it doesn't exist.\n",
    "if not os.path.exists(SAMPLE_IMAGE_PATH):\n",
    "    image_url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "    print(f\"Attempting to download dummy sample image from {image_url}...\")\n",
    "    try:\n",
    "        response = requests.get(image_url, timeout=10) # Timeout after 10 seconds.\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4XX or 5XX).\n",
    "        \n",
    "        # Convert the image content (bytes) to a NumPy array.\n",
    "        image_bytes = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        \n",
    "        # Decode the NumPy array into an OpenCV image.\n",
    "        dummy_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if dummy_image is not None:\n",
    "            cv2.imwrite(SAMPLE_IMAGE_PATH, dummy_image)\n",
    "            print(f\"Created dummy sample image from URL at: {SAMPLE_IMAGE_PATH}. REPLACE IT WITH YOUR OWN TEST IMAGE.\")\n",
    "        else:\n",
    "            print(f\"Failed to decode dummy sample image from URL: {image_url}\")\n",
    "            print(\"Please ensure you have a valid image at SAMPLE_IMAGE_PATH or check the URL.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download dummy sample image from URL {image_url}: {e}\")\n",
    "        print(\"Please ensure you have a working internet connection and the URL is accessible.\")\n",
    "        print(f\"You may need to manually create a placeholder image at '{SAMPLE_IMAGE_PATH}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while creating dummy image: {e}\")\n",
    "        print(f\"Please ensure you have a valid image at '{SAMPLE_IMAGE_PATH}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cc540-7451-4bc2-b927-5bf286f8cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load a Pre-trained YOLO Model.\n",
    "# We'll start with the pre-trained model yolov12n.pt.\n",
    "\n",
    "MODEL_NAME = 'yolo12n.pt'\n",
    "\n",
    "try:\n",
    "    model = YOLO(MODEL_NAME)\n",
    "    print(f\"Successfully loaded pre-trained model: {MODEL_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading pre-trained model: {e}\")\n",
    "    print(\"Ensure you have an internet connection for the first download, or the model file is available.\")\n",
    "\n",
    "# Display model information.\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c18134-70dd-481b-90ee-bd7d2c12a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train (Fine-tune) the Model on the Fall Detection Dataset.\n",
    "# This step requires the dataset to be properly set up with the data.yaml file.\n",
    "\n",
    "# Training parameters.\n",
    "EPOCHS = 50  # Number of training epochs (iterations over the entire dataset).\n",
    "IMG_SIZE = 640 # Image size for training (YOLOv12 default is 640).\n",
    "BATCH_SIZE = 16 # Number of images processed in one go. Reduce if there are Out-of-Memory errors.\n",
    "                # Requires GPU memory.\n",
    "\n",
    "print(\"\\n--- Starting Model Training (Fine-tuning) ---\")\n",
    "print(f\"Dataset configuration: {DATASET_YAML_PATH}\")\n",
    "print(f\"Epochs: {EPOCHS}, Image Size: {IMG_SIZE}, Batch Size: {BATCH_SIZE}\")\n",
    "print(\"This may take a while...\")\n",
    "\n",
    "# Check again if YAML exists before training.\n",
    "if os.path.exists(DATASET_YAML_PATH):\n",
    "    try:\n",
    "        # Start training.\n",
    "        results = model.train(\n",
    "            data=DATASET_YAML_PATH,\n",
    "            epochs=EPOCHS,\n",
    "            imgsz=IMG_SIZE,\n",
    "            batch=BATCH_SIZE,\n",
    "            project='runs/train', # Directory to save training results.\n",
    "            name='fall_detection_exp_2', # Experiment name (sub-folder in project).\n",
    "            patience=10\n",
    "        )\n",
    "        print(\"\\n--- Training Completed ---\")\n",
    "        print(f\"Training results saved in: {results.save_dir}\")\n",
    "        # The best model weights are usually saved as 'best.pt' in the experiment directory.\n",
    "        FINE_TUNED_MODEL_PATH = os.path.join(results.save_dir, 'weights/best.pt')\n",
    "        print(f\"Fine-tuned model saved at: {FINE_TUNED_MODEL_PATH}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during training: {e}\")\n",
    "        print(\"Please check your dataset paths, YAML configuration, and available system resources (RAM/GPU memory).\")\n",
    "        FINE_TUNED_MODEL_PATH = None # Ensure it's None if training fails.\n",
    "else:\n",
    "    print(f\"SKIPPING TRAINING: Dataset YAML file not found at '{DATASET_YAML_PATH}'.\")\n",
    "    print(\"Please set up your dataset and YAML file, then re-run this cell.\")\n",
    "    FINE_TUNED_MODEL_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c098565-2845-4224-ac32-5fd75f348e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Load Your Fine-tuned Model for Inference.\n",
    "FINE_TUNED_MODEL_PATH='runs/train/fall_detection_exp_22/weights/best.pt'\n",
    "\n",
    "if FINE_TUNED_MODEL_PATH and os.path.exists(FINE_TUNED_MODEL_PATH):\n",
    "    print(f\"Loading fine-tuned model from: {FINE_TUNED_MODEL_PATH}\")\n",
    "    try:\n",
    "        fall_detection_model = YOLO(FINE_TUNED_MODEL_PATH)\n",
    "        print(\"Fine-tuned model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading fine-tuned model: {e}\")\n",
    "        fall_detection_model = None\n",
    "elif os.path.exists('runs/train/fall_detection_exp_2/weights/best.pt'): # Fallback if script was run in parts.\n",
    "    FINE_TUNED_MODEL_PATH = 'runs/train/fall_detection_exp_2/weights/best.pt'\n",
    "    print(f\"Attempting to load fine-tuned model from default path: {FINE_TUNED_MODEL_PATH}\")\n",
    "    try:\n",
    "        fall_detection_model = YOLO(FINE_TUNED_MODEL_PATH)\n",
    "        print(\"Fine-tuned model loaded successfully from default path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading fine-tuned model from default path: {e}\")\n",
    "        fall_detection_model = None\n",
    "else:\n",
    "    print(\"Fine-tuned model not available. Please ensure training completed successfully or provide the correct path.\")\n",
    "    print(\"Using the base pre-trained COCO model for person detection demo instead.\")\n",
    "    try:\n",
    "        fall_detection_model = YOLO(MODEL_NAME) # Load base model if fine-tuned is not available\n",
    "        print(f\"Loaded base model {MODEL_NAME} for demo purposes.\")\n",
    "        print(\"This model will detect general objects like 'person' but is NOT fine-tuned for falls.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading base model {MODEL_NAME}: {e}\")\n",
    "        fall_detection_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e400b-0a65-4b31-81d4-78a1214ed853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Perform Inference on a Sample Image (Modified to Save Output).\n",
    "\n",
    "if 'fall_detection_model' not in locals() or fall_detection_model is None:\n",
    "    print(\"Model 'fall_detection_model' not loaded. Please run Cell 6 first.\")\n",
    "elif not os.path.exists(SAMPLE_IMAGE_PATH):\n",
    "    print(f\"Sample image not found at '{os.path.abspath(SAMPLE_IMAGE_PATH)}'. Please check the path in Cell 3.\")\n",
    "else:\n",
    "    print(f\"\\n--- Performing Inference on Image: {os.path.abspath(SAMPLE_IMAGE_PATH)} ---\")\n",
    "    try:\n",
    "        # Perform detection.\n",
    "        results = fall_detection_model(SAMPLE_IMAGE_PATH)\n",
    "\n",
    "        # Get the image with detections plotted on it (this is a BGR NumPy array).\n",
    "        res_plotted = results[0].plot() \n",
    "\n",
    "        # --- Save the output image ---\n",
    "        # Create an output filename.\n",
    "        base_name = os.path.basename(SAMPLE_IMAGE_PATH)\n",
    "        name, ext = os.path.splitext(base_name)\n",
    "        output_filename = f\"detected_{name}{ext}\"\n",
    "        \n",
    "        # Define the full path to save the output image (e.g., in the 'test_samples' folder).\n",
    "        output_image_save_path = os.path.join(os.path.dirname(SAMPLE_IMAGE_PATH), output_filename)\n",
    "        \n",
    "        try:\n",
    "            cv2.imwrite(output_image_save_path, res_plotted)\n",
    "            print(f\"Output image with detections SAVED to: {os.path.abspath(output_image_save_path)}\")\n",
    "        except Exception as e_save:\n",
    "            print(f\"Error saving output image: {e_save}\")\n",
    "        # --- End of saving block ---\n",
    "\n",
    "        # To access and print detection details (bounding boxes, classes, confidences):\n",
    "        print(\"\\n--- Detection Details ---\")\n",
    "        if len(results[0].boxes) == 0:\n",
    "            print(\"No objects detected in the image.\")\n",
    "        else:\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0]) # Bounding box coordinates.\n",
    "                    conf = box.conf[0].item()           # Confidence score.\n",
    "                    cls_id = int(box.cls[0].item())     # Class ID.\n",
    "                    cls_name = fall_detection_model.names[cls_id] # Class name.\n",
    "\n",
    "                    print(f\"Detected: {cls_name} (Confidence: {conf:.2f}) at [{x1}, {y1}, {x2}, {y2}]\")\n",
    "                    if \"fall\" in cls_name.lower(): # Simple check if the class name indicates a fall.\n",
    "                        print(f\"ALERT: Potential fall detected for class '{cls_name}'!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during image inference: {e}\")\n",
    "        print(f\"Make sure '{SAMPLE_IMAGE_PATH}' is a valid image file and the model is loaded correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c4b00a-c500-4bf8-870d-1a21e1d822c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Inference on Video: C:\\Users\\Joao Duarte\\Documents\\IST\\EITT\\test_samples\\test_video.mp4 ---\n",
      "Attempting to write output video to: C:\\Users\\Joao Duarte\\Documents\\IST\\EITT\\test_samples\\detected_manual_test_video_45_Second_Model_Forth_Video.mp4 with 30 FPS, resolution 1920x1080.\n",
      "VideoWriter opened successfully. Processing frames...\n",
      "Estimated total frames in video: 255\n",
      "Frame 1: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [711,282,1246,949]\n",
      "Frame 2: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,281,1245,951]\n",
      "Frame 3: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [713,282,1245,949]\n",
      "Frame 4: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,283,1246,948]\n",
      "Frame 5: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [712,284,1243,952]\n",
      "Frame 6: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [712,285,1242,951]\n",
      "Frame 7: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [710,286,1239,952]\n",
      "Frame 8: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [711,288,1238,951]\n",
      "Frame 9: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [711,291,1238,951]\n",
      "Frame 10: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [712,290,1237,949]\n",
      "Frame 11: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,290,1236,948]\n",
      "Frame 12: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [714,290,1237,946]\n",
      "Frame 13: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [714,290,1237,946]\n",
      "Frame 14: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,290,1239,947]\n",
      "Frame 15: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,290,1238,945]\n",
      "Frame 16: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,291,1243,948]\n",
      "Frame 17: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,291,1243,947]\n",
      "Frame 18: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [718,291,1242,948]\n",
      "Frame 19: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [718,291,1242,946]\n",
      "Frame 20: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,290,1241,947]\n",
      "Frame 21: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [718,289,1241,947]\n",
      "Frame 22: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,289,1240,947]\n",
      "Frame 23: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [718,289,1240,948]\n",
      "Frame 24: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,289,1241,948]\n",
      "Frame 25: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,288,1241,948]\n",
      "Frame 26: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [714,286,1244,943]\n",
      "Frame 27: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,289,1241,948]\n",
      "Frame 28: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [716,290,1241,949]\n",
      "Frame 29: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [715,291,1242,949]\n",
      "Frame 30: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [713,288,1246,943]\n",
      "Frame 31: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [715,293,1244,951]\n",
      "Frame 32: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [715,294,1243,950]\n",
      "Frame 33: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,294,1244,950]\n",
      "Frame 34: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [715,293,1242,951]\n",
      "Frame 35: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [715,292,1243,951]\n",
      "Frame 36: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,290,1246,952]\n",
      "Frame 37: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,291,1250,952]\n",
      "Frame 38: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,292,1248,953]\n",
      "Frame 39: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,292,1250,952]\n",
      "Frame 40: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,291,1248,953]\n",
      "Frame 41: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,291,1247,953]\n",
      "Frame 42: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,292,1242,954]\n",
      "Frame 43: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,293,1242,954]\n",
      "Frame 44: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,293,1243,954]\n",
      "Frame 45: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,295,1243,955]\n",
      "Frame 46: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,294,1243,954]\n",
      "Frame 47: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,295,1242,954]\n",
      "Frame 48: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,294,1242,953]\n",
      "Frame 49: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,294,1243,953]\n",
      "Frame 50: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,293,1245,954]\n",
      "Frame 51: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,293,1245,953]\n",
      "Frame 52: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,293,1245,953]\n",
      "Frame 53: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,293,1245,953]\n",
      "Frame 54: VIDEO ALERT: Potential 'fall' (Conf: 0.88) at [715,293,1249,954]\n",
      "Frame 55: VIDEO ALERT: Potential 'fall' (Conf: 0.88) at [715,293,1250,954]\n",
      "Frame 56: VIDEO ALERT: Potential 'fall' (Conf: 0.88) at [714,295,1251,956]\n",
      "Frame 57: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,294,1246,954]\n",
      "Frame 58: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,292,1244,954]\n",
      "Frame 59: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,291,1245,955]\n",
      "Frame 60: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,290,1246,955]\n",
      "Frame 61: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,289,1246,955]\n",
      "Frame 62: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [714,290,1244,957]\n",
      "Frame 63: VIDEO ALERT: Potential 'fall' (Conf: 0.88) at [714,292,1243,960]\n",
      "Frame 64: VIDEO ALERT: Potential 'fall' (Conf: 0.88) at [715,294,1244,960]\n",
      "Frame 65: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [715,295,1245,959]\n",
      "Frame 66: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,295,1245,958]\n",
      "Frame 67: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,296,1242,958]\n",
      "Frame 68: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [717,296,1242,957]\n",
      "Frame 69: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [717,296,1241,955]\n",
      "Frame 70: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [716,295,1242,955]\n",
      "Frame 71: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,294,1241,952]\n",
      "Frame 72: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,293,1239,952]\n",
      "Frame 73: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,291,1237,952]\n",
      "Frame 74: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,290,1237,948]\n",
      "Frame 75: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,289,1236,949]\n",
      "Frame 76: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [715,287,1238,940]\n",
      "Frame 77: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,286,1237,943]\n",
      "Frame 78: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,287,1238,943]\n",
      "Frame 79: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [716,289,1237,950]\n",
      "Frame 80: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,289,1236,948]\n",
      "Frame 81: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,289,1237,949]\n",
      "Frame 82: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [716,289,1235,949]\n",
      "Frame 83: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,289,1235,949]\n",
      "Frame 84: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [716,289,1235,949]\n",
      "Frame 85: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,289,1235,948]\n",
      "Frame 86: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,289,1235,946]\n",
      "Frame 87: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [716,289,1235,948]\n",
      "Frame 88: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [716,289,1237,948]\n",
      "Frame 89: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [716,289,1236,946]\n",
      "Frame 90: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [715,288,1236,947]\n",
      "Frame 91: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [714,289,1238,946]\n",
      "Frame 92: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [714,289,1237,947]\n",
      "Frame 93: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,289,1237,945]\n",
      "Frame 94: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,289,1236,945]\n",
      "Frame 95: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,290,1237,947]\n",
      "Frame 96: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [714,292,1239,947]\n",
      "Frame 97: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [714,291,1237,944]\n",
      "Frame 98: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,292,1236,944]\n",
      "Frame 99: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [712,287,1242,940]\n",
      "Frame 100: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,291,1241,944]\n",
      "Frame 101: VIDEO ALERT: Potential 'fall' (Conf: 0.83) at [719,290,1240,942]\n",
      "Frame 102: VIDEO ALERT: Potential 'fall' (Conf: 0.83) at [716,284,1244,936]\n",
      "Frame 103: VIDEO ALERT: Potential 'fall' (Conf: 0.83) at [721,284,1236,941]\n",
      "Frame 104: VIDEO ALERT: Potential 'fall' (Conf: 0.83) at [722,283,1231,937]\n",
      "Frame 105: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [716,279,1242,930]\n",
      "Frame 106: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [717,280,1245,932]\n",
      "Frame 107: VIDEO ALERT: Potential 'fall' (Conf: 0.83) at [718,281,1245,932]\n",
      "Frame 108: VIDEO ALERT: Potential 'fall' (Conf: 0.83) at [718,280,1242,931]\n",
      "Frame 109: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [718,279,1243,931]\n",
      "Frame 110: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,275,1240,932]\n",
      "Frame 111: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [715,272,1240,934]\n",
      "Frame 112: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,270,1237,937]\n",
      "Frame 113: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [712,270,1240,939]\n",
      "Frame 114: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [711,270,1241,938]\n",
      "Frame 115: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [711,272,1239,938]\n",
      "Frame 116: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [712,273,1236,936]\n",
      "Frame 117: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [712,274,1238,937]\n",
      "Frame 118: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,272,1236,938]\n",
      "Frame 119: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [714,272,1234,936]\n",
      "Frame 120: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [714,272,1234,934]\n",
      "Frame 121: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,270,1240,930]\n",
      "Frame 122: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [713,270,1241,931]\n",
      "Frame 123: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,269,1241,930]\n",
      "Frame 124: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,271,1244,930]\n",
      "Frame 125: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [714,270,1246,930]\n",
      "Frame 126: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [716,270,1246,928]\n",
      "Frame 127: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [720,273,1236,936]\n",
      "Frame 128: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [721,273,1236,935]\n",
      "Frame 129: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [721,272,1236,933]\n",
      "Frame 130: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [721,272,1236,932]\n",
      "Frame 131: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [722,272,1236,932]\n",
      "Frame 132: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [722,274,1237,933]\n",
      "Frame 133: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [717,272,1247,926]\n",
      "Frame 134: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,275,1246,927]\n",
      "Frame 135: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,277,1246,926]\n",
      "Frame 136: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,276,1244,928]\n",
      "Frame 137: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,275,1244,928]\n",
      "Frame 138: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [723,277,1233,939]\n",
      "Frame 139: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [724,278,1233,940]\n",
      "Frame 140: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,280,1243,931]\n",
      "Frame 141: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [717,280,1242,930]\n",
      "Frame 142: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [724,281,1232,938]\n",
      "Frame 143: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [725,281,1233,938]\n",
      "Frame 144: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [725,281,1234,938]\n",
      "Frame 145: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [725,281,1234,939]\n",
      "Frame 146: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [725,282,1233,939]\n",
      "Frame 147: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [725,282,1234,939]\n",
      "Frame 148: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [724,282,1233,938]\n",
      "Frame 149: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [724,283,1233,938]\n",
      "Frame 150: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [725,283,1233,938]\n",
      "Processed 150/255 frames (58.8%)...\n",
      "Frame 151: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [724,282,1235,941]\n",
      "Frame 152: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [725,282,1235,939]\n",
      "Frame 153: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [725,282,1235,939]\n",
      "Frame 154: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [726,282,1235,940]\n",
      "Frame 155: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [726,281,1236,940]\n",
      "Frame 156: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [727,281,1235,940]\n",
      "Frame 157: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [727,281,1235,940]\n",
      "Frame 158: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [727,280,1234,940]\n",
      "Frame 159: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [729,280,1234,937]\n",
      "Frame 160: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [729,279,1234,938]\n",
      "Frame 161: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [729,278,1233,938]\n",
      "Frame 162: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [729,278,1234,937]\n",
      "Frame 163: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [728,277,1235,938]\n",
      "Frame 164: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [729,278,1233,940]\n",
      "Frame 165: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [731,279,1232,940]\n",
      "Frame 166: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [732,280,1233,939]\n",
      "Frame 167: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [732,278,1233,938]\n",
      "Frame 168: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [733,277,1233,937]\n",
      "Frame 169: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [733,276,1233,938]\n",
      "Frame 170: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [733,274,1232,937]\n",
      "Frame 171: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [733,275,1234,937]\n",
      "Frame 172: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [733,275,1233,937]\n",
      "Frame 173: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [733,275,1233,939]\n",
      "Frame 174: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [733,275,1233,939]\n",
      "Frame 175: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [732,275,1232,941]\n",
      "Frame 176: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [732,276,1231,940]\n",
      "Frame 177: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [733,276,1231,937]\n",
      "Frame 178: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [732,276,1233,938]\n",
      "Frame 179: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [734,276,1236,932]\n",
      "Frame 180: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [733,275,1237,939]\n",
      "Frame 181: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [735,273,1233,939]\n",
      "Frame 182: VIDEO ALERT: Potential 'fall' (Conf: 0.84) at [735,272,1234,940]\n",
      "Frame 183: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,272,1235,941]\n",
      "Frame 184: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,272,1235,941]\n",
      "Frame 185: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,272,1237,940]\n",
      "Frame 186: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,272,1237,941]\n",
      "Frame 187: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,273,1236,941]\n",
      "Frame 188: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,272,1238,942]\n",
      "Frame 189: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [735,273,1238,942]\n",
      "Frame 190: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [735,273,1238,941]\n",
      "Frame 191: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [735,274,1238,944]\n",
      "Frame 192: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [735,275,1235,945]\n",
      "Frame 193: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [735,275,1235,946]\n",
      "Frame 194: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [735,274,1235,945]\n",
      "Frame 195: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [735,274,1238,946]\n",
      "Frame 196: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,276,1238,946]\n",
      "Frame 197: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,277,1236,947]\n",
      "Frame 198: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,280,1236,947]\n",
      "Frame 199: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1236,947]\n",
      "Frame 200: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1237,947]\n",
      "Frame 201: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1235,945]\n",
      "Frame 202: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [733,282,1234,946]\n",
      "Frame 203: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,283,1234,947]\n",
      "Frame 204: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,283,1235,948]\n",
      "Frame 205: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,283,1235,947]\n",
      "Frame 206: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,283,1235,948]\n",
      "Frame 207: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [734,283,1237,947]\n",
      "Frame 208: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,283,1238,946]\n",
      "Frame 209: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,283,1236,946]\n",
      "Frame 210: VIDEO ALERT: Potential 'fall' (Conf: 0.85) at [733,283,1234,948]\n",
      "Frame 211: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1237,949]\n",
      "Frame 212: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1237,949]\n",
      "Frame 213: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1238,948]\n",
      "Frame 214: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [733,281,1236,949]\n",
      "Frame 215: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [733,281,1235,947]\n",
      "Frame 216: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [733,279,1235,947]\n",
      "Frame 217: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [733,278,1235,947]\n",
      "Frame 218: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [733,277,1234,944]\n",
      "Frame 219: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,278,1236,943]\n",
      "Frame 220: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,279,1237,943]\n",
      "Frame 221: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1236,944]\n",
      "Frame 222: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [735,280,1235,945]\n",
      "Frame 223: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,280,1235,944]\n",
      "Frame 224: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,280,1238,948]\n",
      "Frame 225: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,281,1238,949]\n",
      "Frame 226: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [733,281,1237,951]\n",
      "Frame 227: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [733,281,1237,951]\n",
      "Frame 228: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [733,281,1238,950]\n",
      "Frame 229: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [733,281,1239,950]\n",
      "Frame 230: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,281,1236,949]\n",
      "Frame 231: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,279,1236,949]\n",
      "Frame 232: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,278,1234,948]\n",
      "Frame 233: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [734,278,1233,948]\n",
      "Frame 234: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,277,1235,947]\n",
      "Frame 235: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [735,278,1235,946]\n",
      "Frame 236: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,278,1236,948]\n",
      "Frame 237: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,279,1236,947]\n",
      "Frame 238: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,280,1235,947]\n",
      "Frame 239: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [733,280,1237,949]\n",
      "Frame 240: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [734,281,1237,951]\n",
      "Frame 241: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [732,280,1235,956]\n",
      "Frame 242: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [732,281,1234,957]\n",
      "Frame 243: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [731,282,1237,959]\n",
      "Frame 244: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [732,282,1237,959]\n",
      "Frame 245: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [732,282,1240,958]\n",
      "Frame 246: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [732,282,1239,958]\n",
      "Frame 247: VIDEO ALERT: Potential 'fall' (Conf: 0.87) at [732,282,1241,959]\n",
      "Frame 248: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [731,281,1240,958]\n",
      "Frame 249: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [731,282,1240,958]\n",
      "Frame 250: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [731,282,1239,958]\n",
      "Frame 251: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [730,283,1238,959]\n",
      "Frame 252: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [730,283,1239,960]\n",
      "Frame 253: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [730,284,1242,959]\n",
      "Frame 254: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [729,283,1243,958]\n",
      "Frame 255: VIDEO ALERT: Potential 'fall' (Conf: 0.86) at [729,283,1243,959]\n",
      "Reached end of video or failed to read subsequent frame.\n",
      "\n",
      "Video processing finished. Total frames processed: 255.\n",
      "Output video saved to: C:\\Users\\Joao Duarte\\Documents\\IST\\EITT\\test_samples\\detected_manual_test_video_45_Second_Model_Forth_Video.mp4\n",
      "Releasing video capture and writer resources...\n",
      "Video capture could not be opened. Video processing skipped.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Perform Inference on a Sample Video (Manual Drawing with Confidence Filter).\n",
    "\n",
    "if 'fall_detection_model' not in locals() or fall_detection_model is None:\n",
    "    print(\"Model 'fall_detection_model' not loaded. Please run Cell 6 first to load your fine-tuned model.\")\n",
    "    fall_detection_model = None \n",
    "elif not os.path.exists(SAMPLE_VIDEO_PATH):\n",
    "    print(f\"Sample video not found at '{os.path.abspath(SAMPLE_VIDEO_PATH)}'. Please check the path in Cell 3.\")\n",
    "else:\n",
    "    print(f\"\\n--- Performing Inference on Video: {os.path.abspath(SAMPLE_VIDEO_PATH)} ---\")\n",
    "\n",
    "    cap = cv2.VideoCapture(SAMPLE_VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {os.path.abspath(SAMPLE_VIDEO_PATH)}\")\n",
    "    else:\n",
    "        base_name_video = os.path.basename(SAMPLE_VIDEO_PATH)\n",
    "        name_video, _ = os.path.splitext(base_name_video) # ext_video not used for output name.\n",
    "        output_video_filename = f\"detected_manual_{name_video}_45_Second_Model_Forth_Video.mp4\" # Indicate manual drawing in filename.\n",
    "        output_video_path = os.path.join(os.path.dirname(SAMPLE_VIDEO_PATH), output_video_filename)\n",
    "        \n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps_video = cap.get(cv2.CAP_PROP_FPS) \n",
    "        \n",
    "        if fps_video == 0 or fps_video is None:\n",
    "            print(f\"Warning: Video FPS reported as {fps_video}. Defaulting to 25 FPS for output video.\")\n",
    "            fps_video = 25 \n",
    "        else:\n",
    "            fps_video = int(fps_video)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "        \n",
    "        print(f\"Attempting to write output video to: {os.path.abspath(output_video_path)} with {fps_video} FPS, resolution {frame_width}x{frame_height}.\")\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps_video, (frame_width, frame_height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"Error: Failed to open VideoWriter for path: {os.path.abspath(output_video_path)}\")\n",
    "        else:\n",
    "            print(\"VideoWriter opened successfully. Processing frames...\")\n",
    "            try:\n",
    "                frame_count = 0\n",
    "                total_frames_estimate = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                print(f\"Estimated total frames in video: {total_frames_estimate if total_frames_estimate > 0 else 'N/A'}\")\n",
    "\n",
    "                while cap.isOpened():\n",
    "                    ret, original_frame = cap.read() # Read the original frame.\n",
    "                    if not ret:\n",
    "                        if frame_count == 0:\n",
    "                             print(\"Failed to read the first frame. Video might be empty or corrupted.\")\n",
    "                        else:\n",
    "                             print(\"Reached end of video or failed to read subsequent frame.\")\n",
    "                        break\n",
    "                    \n",
    "                    frame_count += 1\n",
    "                    # Make a copy of the frame to draw on, if you want to keep original_frame pristine for other uses.\n",
    "                    frame_to_draw_on = original_frame.copy()\n",
    "\n",
    "                    results = fall_detection_model(original_frame, stream=True, verbose=False) \n",
    "\n",
    "                    for result in results: # result is a Results object for the current frame.\n",
    "                        # --- MANUAL DRAWING BLOCK ---\n",
    "                        if len(result.boxes) > 0:\n",
    "                            for box in result.boxes:\n",
    "                                conf_score = box.conf[0].item()\n",
    "                                \n",
    "                                if conf_score > 0.45: \n",
    "                                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                                    cls_id = int(box.cls[0].item())\n",
    "                                    \n",
    "                                    label = \"Unknown\"\n",
    "                                    if 0 <= cls_id < len(fall_detection_model.names):\n",
    "                                        cls_name = fall_detection_model.names[cls_id]\n",
    "                                        label = f\"{cls_name} {conf_score:.2f}\"\n",
    "                                    else: # Fallback if class ID is out of range\n",
    "                                        label = f\"CLS_ID_{cls_id} {conf_score:.2f}\"\n",
    "                                        print(f\"Warning: Frame {frame_count} - Detected class ID {cls_id} is out of range for model names.\")\n",
    "\n",
    "                                    # Draw rectangle.\n",
    "                                    cv2.rectangle(frame_to_draw_on, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
    "                                    \n",
    "                                    # Put label text above the rectangle.\n",
    "                                    # Calculate text size to draw a filled box behind text for better readability.\n",
    "                                    (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                                    cv2.rectangle(frame_to_draw_on, (x1, y1 - label_height - baseline), (x1 + label_width, y1), (0, 255, 0), cv2.FILLED)\n",
    "                                    cv2.putText(frame_to_draw_on, label, (x1, y1 - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1) # Black text\n",
    "\n",
    "                                    # Alert printing logic (can be kept here or moved based on preference).\n",
    "                                    if \"fall\" in cls_name.lower(): # Using cls_name obtained above.\n",
    "                                        print(f\"Frame {frame_count}: VIDEO ALERT: Potential '{cls_name}' (Conf: {conf_score:.2f}) at [{x1},{y1},{x2},{y2}]\")\n",
    "                        # --- END OF MANUAL DRAWING BLOCK ---\n",
    "                        \n",
    "                        out.write(frame_to_draw_on) # Write the frame with manual detections\n",
    "\n",
    "                    if total_frames_estimate > 0 and frame_count % (fps_video * 5) == 0 : \n",
    "                         progress_percent = (frame_count / total_frames_estimate) * 100\n",
    "                         print(f\"Processed {frame_count}/{total_frames_estimate} frames ({progress_percent:.1f}%)...\")\n",
    "                    elif frame_count % (fps_video * 10) == 0 : \n",
    "                         print(f\"Processed {frame_count} frames...\")\n",
    "\n",
    "                if frame_count > 0:\n",
    "                    print(f\"\\nVideo processing finished. Total frames processed: {frame_count}.\")\n",
    "                    print(f\"Output video saved to: {os.path.abspath(output_video_path)}\")\n",
    "                elif 'out' in locals() and out.isOpened():\n",
    "                    print(\"\\nNo frames were processed or video was empty.\")\n",
    "                    print(f\"An empty or short video might have been created at: {os.path.abspath(output_video_path)}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during video inference processing: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc() \n",
    "            finally:\n",
    "                print(\"Releasing video capture and writer resources...\")\n",
    "                cap.release()\n",
    "                if 'out' in locals() and out.isOpened():\n",
    "                    out.release()\n",
    "\n",
    "if 'fall_detection_model' not in locals() or fall_detection_model is None:\n",
    "    if not ('cap' in locals() and 'out' in locals()): \n",
    "        print(\"Model not loaded. Video processing skipped.\")\n",
    "elif not os.path.exists(SAMPLE_VIDEO_PATH):\n",
    "    if not ('cap' in locals() and 'out' in locals()):\n",
    "        print(f\"Sample video not found at '{os.path.abspath(SAMPLE_VIDEO_PATH)}'. Video processing skipped.\")\n",
    "elif 'cap' in locals() and not cap.isOpened() and not ('out' in locals() and out.isOpened()):\n",
    "    print(\"Video capture could not be opened. Video processing skipped.\")\n",
    "\n",
    "if os.path.exists(SAMPLE_IMAGE_PATH) and ('fall_detection_model' in locals() and fall_detection_model is not None):\n",
    "    if not os.path.exists(SAMPLE_VIDEO_PATH): \n",
    "        print(\"\\nTip: If you don't have a video, you can test single image 'streaming' logic like this (in a new cell):\")\n",
    "        print(\"# results_img_stream = fall_detection_model(SAMPLE_IMAGE_PATH, stream=True)\")\n",
    "        print(\"# for res_img in results_img_stream: print(res_img.boxes)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorchgpu)",
   "language": "python",
   "name": "pytorchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
